{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myclasses.sql_executor import SQLExecutor\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create an instance of SQLExecutor\n",
    "    sql_executor = SQLExecutor()\n",
    "\n",
    "    # Example SQL query\n",
    "    query = \"\"\"\n",
    "        SELECT \n",
    "            (net_income / num_beds) as net_income,\n",
    "            year,\n",
    "            tot_fund_balance,\n",
    "            ownership,\n",
    "            acct_payable,\n",
    "            acct_rec,\n",
    "            total_liabilities,\n",
    "            current_ratio,\n",
    "            quick_ratio,\n",
    "            (tot_days / tot_bed_days_avail) as fill_rate,\n",
    "            overhead_nonsalary_costs,\n",
    "            tot_salaries,\n",
    "            cash,\n",
    "            chow_last_12mos,\n",
    "            region,\n",
    "            state,\n",
    "            state_lean,\n",
    "            county_ssa,\n",
    "            zip,\n",
    "            tot_discharge_tot,\n",
    "            def_score,\n",
    "            fine_tot,\n",
    "            fine_cnt,\n",
    "            resfamcouncil,\n",
    "            sprinkler_status,\n",
    "            overall_rating,\n",
    "            quality_rating,\n",
    "            staffing_rating,\n",
    "            rn_staffing_rating,\n",
    "            aidhrd,\n",
    "            vochrd,\n",
    "            rnhrd,\n",
    "            totlichrd,\n",
    "            tothrd,\n",
    "            pthrd,\n",
    "            weighted_all_cycles_score,\n",
    "            certification,\n",
    "            snf_avg_stay_len_title_tot,\n",
    "            pop_over_70,\n",
    "            over_70_pct,\n",
    "            has_outpatient,\n",
    "            bedcert,\n",
    "            contract_labor\n",
    "            \n",
    "        FROM Master\n",
    "        WHERE year in (2020, 2021, 2022)\n",
    "        ORDER BY prov_id;\n",
    "        \"\"\"\n",
    "\n",
    "    # Execute the query and get the result as a DataFrame\n",
    "    df = sql_executor.execute_query(query)\n",
    "\n",
    "# Assuming NA contract_labor means the Nursing home does have contract_labor\n",
    "df[['contract_labor']] = df[['contract_labor']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_income</th>\n",
       "      <th>year</th>\n",
       "      <th>tot_fund_balance</th>\n",
       "      <th>acct_payable</th>\n",
       "      <th>acct_rec</th>\n",
       "      <th>total_liabilities</th>\n",
       "      <th>current_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>fill_rate</th>\n",
       "      <th>overhead_nonsalary_costs</th>\n",
       "      <th>...</th>\n",
       "      <th>rnhrd</th>\n",
       "      <th>totlichrd</th>\n",
       "      <th>tothrd</th>\n",
       "      <th>pthrd</th>\n",
       "      <th>weighted_all_cycles_score</th>\n",
       "      <th>snf_avg_stay_len_title_tot</th>\n",
       "      <th>pop_over_70</th>\n",
       "      <th>over_70_pct</th>\n",
       "      <th>bedcert</th>\n",
       "      <th>contract_labor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.666900e+04</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>3.666900e+04</td>\n",
       "      <td>3.666900e+04</td>\n",
       "      <td>3.666900e+04</td>\n",
       "      <td>3.666900e+04</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>3.666900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>28048.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "      <td>36669.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.244034e+03</td>\n",
       "      <td>2020.814421</td>\n",
       "      <td>3.099135e+04</td>\n",
       "      <td>8.145473e+03</td>\n",
       "      <td>1.817111e+04</td>\n",
       "      <td>1.277870e+05</td>\n",
       "      <td>10.474222</td>\n",
       "      <td>5.640781</td>\n",
       "      <td>0.725666</td>\n",
       "      <td>5.628024e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680087</td>\n",
       "      <td>1.581166</td>\n",
       "      <td>3.875040</td>\n",
       "      <td>0.073617</td>\n",
       "      <td>64.156051</td>\n",
       "      <td>2.201931</td>\n",
       "      <td>67758.346014</td>\n",
       "      <td>0.119606</td>\n",
       "      <td>0.986599</td>\n",
       "      <td>7237.352978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.655835e+04</td>\n",
       "      <td>0.758252</td>\n",
       "      <td>3.091946e+05</td>\n",
       "      <td>4.522035e+04</td>\n",
       "      <td>1.270708e+05</td>\n",
       "      <td>6.512118e+05</td>\n",
       "      <td>1093.324057</td>\n",
       "      <td>652.646874</td>\n",
       "      <td>2.580607</td>\n",
       "      <td>5.619001e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.430981</td>\n",
       "      <td>0.785252</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>67.555344</td>\n",
       "      <td>5.896135</td>\n",
       "      <td>150044.498309</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>0.299421</td>\n",
       "      <td>8853.565609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.700283e+06</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>-9.221566e+06</td>\n",
       "      <td>-1.550743e+06</td>\n",
       "      <td>-4.259891e+05</td>\n",
       "      <td>-1.621231e+06</td>\n",
       "      <td>-816.141414</td>\n",
       "      <td>-4793.230126</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>5.767761e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.503410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.030065</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.187726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.442894e+03</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>-3.767515e+03</td>\n",
       "      <td>1.744122e+03</td>\n",
       "      <td>6.210200e+03</td>\n",
       "      <td>9.168044e+03</td>\n",
       "      <td>0.667167</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.606571</td>\n",
       "      <td>3.531894e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>1.388810</td>\n",
       "      <td>3.466260</td>\n",
       "      <td>0.038890</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.727882</td>\n",
       "      <td>3303.000000</td>\n",
       "      <td>0.101151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3314.414141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.636360e+03</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>8.707318e+03</td>\n",
       "      <td>3.748097e+03</td>\n",
       "      <td>9.974263e+03</td>\n",
       "      <td>2.066852e+04</td>\n",
       "      <td>1.277315</td>\n",
       "      <td>0.137777</td>\n",
       "      <td>0.724408</td>\n",
       "      <td>4.745570e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642225</td>\n",
       "      <td>1.508395</td>\n",
       "      <td>3.810080</td>\n",
       "      <td>0.067630</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.243656</td>\n",
       "      <td>16434.000000</td>\n",
       "      <td>0.118884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5510.663043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.427323e+03</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>3.161471e+04</td>\n",
       "      <td>7.994560e+03</td>\n",
       "      <td>1.543454e+04</td>\n",
       "      <td>5.677432e+04</td>\n",
       "      <td>2.492608</td>\n",
       "      <td>0.812930</td>\n",
       "      <td>0.821013</td>\n",
       "      <td>6.211382e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754160</td>\n",
       "      <td>1.677150</td>\n",
       "      <td>4.067870</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>2.229352</td>\n",
       "      <td>66948.000000</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9087.793814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.401623e+06</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.869957e+07</td>\n",
       "      <td>2.027600e+06</td>\n",
       "      <td>1.701048e+07</td>\n",
       "      <td>2.896913e+07</td>\n",
       "      <td>203696.688525</td>\n",
       "      <td>119671.689243</td>\n",
       "      <td>321.645833</td>\n",
       "      <td>2.146148e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.384050</td>\n",
       "      <td>7.929440</td>\n",
       "      <td>16.326920</td>\n",
       "      <td>1.450440</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>175.703125</td>\n",
       "      <td>973386.000000</td>\n",
       "      <td>0.453558</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>825561.760417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         net_income          year  tot_fund_balance  acct_payable  \\\n",
       "count  3.666900e+04  36669.000000      3.666900e+04  3.666900e+04   \n",
       "mean   1.244034e+03   2020.814421      3.099135e+04  8.145473e+03   \n",
       "std    2.655835e+04      0.758252      3.091946e+05  4.522035e+04   \n",
       "min   -1.700283e+06   2020.000000     -9.221566e+06 -1.550743e+06   \n",
       "25%   -4.442894e+03   2020.000000     -3.767515e+03  1.744122e+03   \n",
       "50%    1.636360e+03   2021.000000      8.707318e+03  3.748097e+03   \n",
       "75%    8.427323e+03   2021.000000      3.161471e+04  7.994560e+03   \n",
       "max    1.401623e+06   2022.000000      1.869957e+07  2.027600e+06   \n",
       "\n",
       "           acct_rec  total_liabilities  current_ratio    quick_ratio  \\\n",
       "count  3.666900e+04       3.666900e+04   36669.000000   36669.000000   \n",
       "mean   1.817111e+04       1.277870e+05      10.474222       5.640781   \n",
       "std    1.270708e+05       6.512118e+05    1093.324057     652.646874   \n",
       "min   -4.259891e+05      -1.621231e+06    -816.141414   -4793.230126   \n",
       "25%    6.210200e+03       9.168044e+03       0.667167       0.006828   \n",
       "50%    9.974263e+03       2.066852e+04       1.277315       0.137777   \n",
       "75%    1.543454e+04       5.677432e+04       2.492608       0.812930   \n",
       "max    1.701048e+07       2.896913e+07  203696.688525  119671.689243   \n",
       "\n",
       "          fill_rate  overhead_nonsalary_costs  ...         rnhrd  \\\n",
       "count  36669.000000              3.666900e+04  ...  36669.000000   \n",
       "mean       0.725666              5.628024e+04  ...      0.680087   \n",
       "std        2.580607              5.619001e+04  ...      0.363639   \n",
       "min        0.002740              5.767761e+01  ...      0.000000   \n",
       "25%        0.606571              3.531894e+04  ...      0.489300   \n",
       "50%        0.724408              4.745570e+04  ...      0.642225   \n",
       "75%        0.821013              6.211382e+04  ...      0.754160   \n",
       "max      321.645833              2.146148e+06  ...      7.384050   \n",
       "\n",
       "          totlichrd        tothrd         pthrd  weighted_all_cycles_score  \\\n",
       "count  36669.000000  36669.000000  36669.000000               28048.000000   \n",
       "mean       1.581166      3.875040      0.073617                  64.156051   \n",
       "std        0.430981      0.785252      0.069285                  67.555344   \n",
       "min        0.000000      1.503410      0.000000                   0.000000   \n",
       "25%        1.388810      3.466260      0.038890                  22.000000   \n",
       "50%        1.508395      3.810080      0.067630                  44.000000   \n",
       "75%        1.677150      4.067870      0.080900                  82.000000   \n",
       "max        7.929440     16.326920      1.450440                1118.000000   \n",
       "\n",
       "       snf_avg_stay_len_title_tot    pop_over_70   over_70_pct       bedcert  \\\n",
       "count                36669.000000   36669.000000  36669.000000  36669.000000   \n",
       "mean                     2.201931   67758.346014      0.119606      0.986599   \n",
       "std                      5.896135  150044.498309      0.031257      0.299421   \n",
       "min                      0.006042      84.000000      0.030065      0.000840   \n",
       "25%                      0.727882    3303.000000      0.101151      1.000000   \n",
       "50%                      1.243656   16434.000000      0.118884      1.000000   \n",
       "75%                      2.229352   66948.000000      0.135104      1.000000   \n",
       "max                    175.703125  973386.000000      0.453558      5.555556   \n",
       "\n",
       "       contract_labor  \n",
       "count    36669.000000  \n",
       "mean      7237.352978  \n",
       "std       8853.565609  \n",
       "min          0.187726  \n",
       "25%       3314.414141  \n",
       "50%       5510.663043  \n",
       "75%       9087.793814  \n",
       "max     825561.760417  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_income(data):\n",
    "\n",
    "    if data >= 6000:\n",
    "        return '5'\n",
    "    elif data >= 3000:\n",
    "        return '4'\n",
    "    elif data >= 1000:\n",
    "        return '3'\n",
    "    elif data >= -1000:\n",
    "        return '2'\n",
    "    elif data >= -4000:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "    \n",
    "df['net_income'] = df['net_income'].apply(bin_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['net_income']\n",
    "df = df.drop(columns='net_income')\n",
    "\n",
    "# Select columns where data type is text (object)\n",
    "text_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create dummy variables for text columns\n",
    "df_encoded = pd.get_dummies(df, columns=text_columns)\n",
    "\n",
    "# Convert all columns to numeric type\n",
    "df_encoded = df_encoded.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Extract target variable (y) and independent variables (X)\n",
    "X = df_encoded.iloc[:, 2:].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap.umap_ as umap\n",
    "\n",
    "# # Assuming X_train is your training data\n",
    "\n",
    "# # Define UMAP reducer\n",
    "# reducer = umap.UMAP(n_components=8)\n",
    "\n",
    "# # Fit and transform the training data\n",
    "# umap_embeddings = reducer.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 11:27:07.496685: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-24 11:27:07.497229: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-24 11:27:07.502557: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-24 11:27:07.561725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 11:27:09.191969: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-24 11:27:09.907109: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-04-24 11:27:09.907144: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: ehan-HP-Pavilion-Laptop-15-cs3xxx\n",
      "2024-04-24 11:27:09.907150: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: ehan-HP-Pavilion-Laptop-15-cs3xxx\n",
      "2024-04-24 11:27:09.907272: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 545.29.6\n",
      "2024-04-24 11:27:09.907293: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 545.29.6\n",
      "2024-04-24 11:27:09.907298: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:248] kernel version seems to match DSO: 545.29.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.3105 - loss: 1.9398 - val_accuracy: 0.3188 - val_loss: 1.6557\n",
      "Epoch 2/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.3179 - loss: 1.6597 - val_accuracy: 0.3188 - val_loss: 1.6556\n",
      "Epoch 3/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.3211 - loss: 1.6566 - val_accuracy: 0.3188 - val_loss: 1.6559\n",
      "Epoch 4/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.3186 - loss: 1.6607 - val_accuracy: 0.3188 - val_loss: 1.6556\n",
      "Epoch 5/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.3180 - loss: 1.6609 - val_accuracy: 0.3188 - val_loss: 1.6556\n",
      "Epoch 6/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.3249 - loss: 1.6563 - val_accuracy: 0.3188 - val_loss: 1.6555\n",
      "Epoch 7/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.3216 - loss: 1.6622 - val_accuracy: 0.3188 - val_loss: 1.6556\n",
      "Epoch 8/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.3309 - loss: 1.6464 - val_accuracy: 0.3188 - val_loss: 1.6557\n",
      "Epoch 9/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.3201 - loss: 1.6541 - val_accuracy: 0.3188 - val_loss: 1.6559\n",
      "Epoch 10/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.3223 - loss: 1.6583 - val_accuracy: 0.3188 - val_loss: 1.6558\n",
      "Epoch 11/30\n",
      "\u001b[1m2934/2934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.3191 - loss: 1.6631 - val_accuracy: 0.3188 - val_loss: 1.6556\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode target values into integers\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Convert integer target values to one-hot encoded format\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train_encoded = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "\n",
    "# Define the architecture of the neural network\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(2, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # Change activation function for multi-classification\n",
    "])\n",
    "\n",
    "# Compile the model with categorical_crossentropy loss\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Change loss and metrics\n",
    "\n",
    "# Define early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train_encoded, epochs=30, batch_size=6, validation_split=0.2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, median_absolute_error, max_error, mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "# Apply the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# R² Score (Coefficient of Determination)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Median Absolute Error\n",
    "mabe = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Max Error\n",
    "max_error_value = max_error(y_test, y_pred)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Explained Variance Score\n",
    "explained_variance = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Root Mean Squared Error: ${:.2f}\".format(rmse))\n",
    "print(\"Median Absolute Error: ${:.2f}\".format(mabe))\n",
    "print(\"Mean Absolute Error: ${:.2f}\".format(mae))\n",
    "print(\"Max Error: ${:.2f}\".format(max_error_value))\n",
    "print(\"R² Score (Coefficient of Determination): {:.5f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert values to thousands\n",
    "y_test_thousands = y_test / 1000\n",
    "y_pred_thousands = y_pred / 1000\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_thousands, y_pred_thousands, color='blue', alpha=0.5, s=1)  # Scatter plot of actual vs. predicted values with smaller point size\n",
    "plt.plot([y_test_thousands.min(), y_test_thousands.max()], [y_test_thousands.min(), y_test_thousands.max()], 'k--', lw=1)  # Plot the diagonal line\n",
    "plt.xlabel('Actual (thousands)')\n",
    "plt.ylabel('Predicted (thousands)')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "\n",
    "# Set axis limits to show the actual values\n",
    "plt.xlim(left=y_test_thousands.min(), right=y_test_thousands.max())\n",
    "plt.ylim(bottom=y_test_thousands.min(), top=y_test_thousands.max())\n",
    "\n",
    "# Add light gridlines\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
